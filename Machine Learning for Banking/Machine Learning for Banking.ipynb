{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom matplotlib import style\nstyle.use('ggplot')\npd.set_option('display.float_format', lambda x: '%.5f' % x)\npd.options.display.max_columns = 100\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV,KFold,StratifiedKFold\nimport lightgbm as lgb\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/janatahack-machine-learning-for-banking/train_fNxu4vz.csv\")\ntest  = pd.read_csv(\"../input/janatahack-machine-learning-for-banking/test_fjtUOL8.csv\")\nSubmission = test[['Loan_ID']]\ntest.drop(\"Loan_ID\",axis=1,inplace=True)\ntrain.drop(\"Loan_ID\",axis=1,inplace=True)\nprint (train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. There are missing values in Length_Employed, Home_Owner, Annual_Income, and Months_Since_Delinquency variables in both Train and Test datasets. \n2. The dataset has a mix of Object, Float and int variables.\n3. Dependent variable is categorical in nature with 3 levels. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Loan_Amount_Requested'] = train['Loan_Amount_Requested'].apply(lambda x: x.replace(\",\",\"\")).astype(float)\ntest['Loan_Amount_Requested'] = test['Loan_Amount_Requested'].apply(lambda x: x.replace(\",\",\"\")).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Loan_Amount_Requested'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train['Loan_Amount_Requested'].quantile(0.25)\nQ3 = train['Loan_Amount_Requested'].quantile(0.75)\nIQR = Q3-Q1\nLower_Range = Q1-1.5*IQR\nUpper_Range = Q3+1.5*IQR\nprint (\"Values Below {} and Values above {} are considered as outliers in Loan_Amount_Requested Variable\".format(Lower_Range,Upper_Range))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['Loan_Amount_Requested'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We cannot make out anything from the distribution above, although it might be considered tending towards Positively skewed distribution. \n2. The minimum value is 500 and Maximum is 35000, so the range is 34500.\n3. The median is 12075 with a standard deviation of 8281. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Length_Employed'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Length_Employed'].value_counts(dropna=False).plot(kind='bar')\n# There are lot of missing values\n# Most of them have been employed for more than 10 years. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Home_Owner'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Home_Owner'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Home_Owner'].value_counts(dropna=False).plot(kind='bar')\n# There are lot of missing values\n# Most of them have been employed for more than 10 years. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the value count of Other and None are negligible as compared to the size of the dataset, they can be combined with any\n# other value.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Annual_Income'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(np.log1p(train['Annual_Income'].dropna()),kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['Annual_Income']>1000000,'Annual_Income'] = train['Annual_Income'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['Annual_Income']>1000000,'Annual_Income'] = test['Annual_Income'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. As we can see in the above plot, a lot of income variables are between 4000 and 100000.\n2. There seem to be some outliers that need to be explored.\n3. Outliers are the reason for high mean.\n4. There are a few people whose incomes are more than a million.\n5. We can also see that Log transformed Annual_Income looks perfectly normal.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['Annual_Income'] >= 100000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train['Annual_Income'].quantile(0.25)\nQ3 = train['Annual_Income'].quantile(0.75)\nIQR = Q3-Q1\nLower_Range = Q1-1.5*IQR\nUpper_Range = Q3+1.5*IQR\nprint (\"Values Below {} and Values above {} are considered as outliers in Annual_Income Variable\".format(Lower_Range,Upper_Range))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Income_Verified'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Income_Verified'].value_counts(dropna=False).plot(kind='bar')\n# There are no missing values here, but a large portion of incomes are not verified. \n# There are also significant observations where the income source is verified but not the income.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Purpose_Of_Loan'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Purpose_Of_Loan'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Purpose_Of_Loan'].value_counts(dropna=False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Debt_Consolidation and Credit_Card seem to be the common reasons for loan application.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Debt_To_Income'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['Debt_To_Income'])\n# Seems to be normally distributed. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. As per the description of the variable, it is 'A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested loan, divided by the borrower’s self-reported monthly income.'\n2. A value of 0 in Debt_to_Income ratio seems strange. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Inquiries_Last_6Mo'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Inquiries_Last_6Mo'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Inquiries_Last_6Mo'].value_counts(dropna=False).plot(kind='bar')\n# Most of the borrowers have not made any inquiries in the last 6 months. There are a few who have made 8 inquiries as well.\n# No missing values in this variable.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Months_Since_Deliquency'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. More than 50% missing values in this variable. We have to check how useful this variable is.\n2. One way is , if the Months_Since_Deliquency is low, then the interest charged might be higher and vice versa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Number_Open_Accounts'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Number_Open_Accounts'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Number_Open_Accounts'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Most of the people have more than 6 open accounts currently.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Total_Accounts'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Total_Accounts'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Number_Open_Accounts','Total_Accounts']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We can find the number of accounts closed by the customers. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Gender'].value_counts(dropna=False).plot(kind='bar')\n# No missing values here.\n# Male population is greater than Female.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dependent Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Interest_Rate'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Interest_Rate'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Interest Rate 2 seems to be more popular. Followed by 3 and 1.\n2. Around 50% of them are applicable for Interest Rate category 2.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Bi-Variate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Length_Employed')['Loan_Amount_Requested'].agg(['count','min','max','mean','median','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We can see that the average Loan Amount Requested is maximum for people with 10+ years of employment.\n2. The maximum value of the Loan_Amount_Requested is same for all levels of employment although minimum amount differs.\n3. The average Loan_Amount_Requested is minimum for people with <1 year of being employed. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Home_Owner')['Loan_Amount_Requested'].agg(['count','min','max','mean','median','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We can see the average Loan_Amount_Requested is maximum for people with Home_Owner status as Mortgage.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.scatterplot(x=train['Loan_Amount_Requested'],y=train['Annual_Income'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We can see the points at the top of the plot that although the Annual_Income is high, the Loan_Amount_Requested is low.\n2. We can also see a few Annual_Incomes that are more than 1000000.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Purpose_Of_Loan')['Loan_Amount_Requested'].agg(['count','min','max','mean','median','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. As we can see from the table above, the average loan amount requested is highest for small business followed by debt_consolidation.\n2. Average income requested is also high for House loans. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Interest_Rate')['Loan_Amount_Requested'].agg(['count','min','max','mean','median','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Clearly, there is a distinction between the average loan amount requested for the type of interest rates.\n2. Average Loan Amount seems to be high for Interest Rate category 3 and there is not much between the loan amount for categories 1 and 2. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Interest_Rate')['Annual_Income'].agg(['count','min','max','mean','median','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. The mean Annual_Income for Interest Rate Category 1 is the highest. And it is almost the same for Interest Rate categories 2 and 3. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Feature Generation, Feature Extraction, etc ..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in [train,test]:\n    # Filling Missing Values\n    df['Length_Employed'].fillna(\"Missing\",inplace=True)\n    df['Home_Owner'].fillna(\"Missing\",inplace=True)\n    df['Home_Owner'].replace({\"Other\":\"New\",\"None\":\"New\"},inplace=True) # Combining Other and None to a single Category\n    df['Annual_Income'].fillna(df['Annual_Income'].mean(),inplace=True) # Filling missing value with median income\n    df['Deliquency_Status'] = df['Months_Since_Deliquency'].apply(lambda x: 1 if x>0 else 0)\n    \n    # Feature Generation\n    df['Closed_Accounts'] = df['Total_Accounts']-df['Number_Open_Accounts']\n    df['Monthly_Income'] = df['Annual_Income']/12\n    df.drop(\"Months_Since_Deliquency\",axis=1,inplace=True)\n    df['Loan_Amount_As_Pct_Of_Income'] = np.round((df['Loan_Amount_Requested']/df['Annual_Income'])*100,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def income_bracket(x):\n    if x<=30000:\n        return \"Low\"\n    elif (x>30000 and x<=60000):\n        return \"Medium\"\n    elif (x>60000 and x<=90000):\n        return \"High\"\n    else:\n        return \"Very High\"\ndef loan_amount_bracket(x):\n    if x<=10000:\n        return \"Low\"\n    elif (x>10000 and x<=20000):\n        return \"Medium\"\n    elif (x>20000 and x<=30000):\n        return \"High\"\n    else:\n        return \"Very High\"\n    \nfor df in [train,test]:\n    df['Income_Bracket'] = df['Annual_Income'].apply(income_bracket)\n    df['Loan_Amount_Bracket'] = df['Loan_Amount_Requested'].apply(loan_amount_bracket)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Groupby Features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = train.groupby('Home_Owner').agg(agg_func)\nagg_func.columns = [ 'Home_Owner_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntrain = train.merge(agg_func, on=['Home_Owner'], how='left')\n\nagg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = test.groupby('Home_Owner').agg(agg_func)\nagg_func.columns = [ 'Home_Owner_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntest = test.merge(agg_func, on=['Home_Owner'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = train.groupby('Purpose_Of_Loan').agg(agg_func)\nagg_func.columns = [ 'Purpose_Of_Loan_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntrain = train.merge(agg_func, on=['Purpose_Of_Loan'], how='left')\n\nagg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = test.groupby('Purpose_Of_Loan').agg(agg_func)\nagg_func.columns = [ 'Purpose_Of_Loan_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntest = test.merge(agg_func, on=['Purpose_Of_Loan'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = train.groupby('Length_Employed').agg(agg_func)\nagg_func.columns = [ 'Length_Employed_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntrain = train.merge(agg_func, on=['Length_Employed'], how='left')\n\nagg_func = {\n    'Loan_Amount_Requested': ['min','max','mean','median','std']    \n}\nagg_func = test.groupby('Length_Employed').agg(agg_func)\nagg_func.columns = [ 'Length_Employed_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntest = test.merge(agg_func, on=['Length_Employed'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func = {\n    'Annual_Income': ['min','max','mean','median','std']    \n}\nagg_func = train.groupby('Length_Employed').agg(agg_func)\nagg_func.columns = [ 'Length_Employed_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntrain = train.merge(agg_func, on=['Length_Employed'], how='left')\n\nagg_func = {\n    'Annual_Income': ['min','max','mean','median','std']    \n}\nagg_func = test.groupby('Length_Employed').agg(agg_func)\nagg_func.columns = [ 'Length_Employed_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntest = test.merge(agg_func, on=['Length_Employed'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func = {\n    'Annual_Income': ['min','max','mean','median','std']    \n}\nagg_func = train.groupby('Purpose_Of_Loan').agg(agg_func)\nagg_func.columns = [ 'Purpose_Of_Loan_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntrain = train.merge(agg_func, on=['Purpose_Of_Loan'], how='left')\n\nagg_func = {\n    'Annual_Income': ['min','max','mean','median','std']    \n}\nagg_func = test.groupby('Purpose_Of_Loan').agg(agg_func)\nagg_func.columns = [ 'Purpose_Of_Loan_' + ('_'.join(col).strip()) for col in agg_func.columns.values]\nagg_func.reset_index(inplace=True)\ntest = test.merge(agg_func, on=['Purpose_Of_Loan'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [col for col in train.columns if train[col].dtype==\"object\"]\nfor col in cols:\n    train[col] = train[col].astype('category')\n    train[col] = train[col].cat.codes\n    \n    test[col] = test[col].astype('category')\n    test[col] = test[col].cat.codes\n    \ncols = ['Number_Open_Accounts','Total_Accounts','Closed_Accounts','Inquiries_Last_6Mo']\nfor item in cols:\n    train[item] = train[item].astype('category')\n    train[item] = train[item].cat.codes\n    \n    test[item] = test[item].astype('category')\n    test[item] = test[item].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [col for col in train.columns if col not in ['Length_Employed','Home_Owner','Income_Verified','Purpose_Of_Loan','Inquiries_Last_6Mo','Number_Open_Accounts','Total_Accounts','Gender','Interest_Rate','Deliquency_Status','Closed_Accounts','Income_Bracket','Loan_Amount_Bracket','Count_Of_Length_Of_Employment','Count_Of_Home_Owner','Count_Of_Income_Verified','Count_Of_Purpose_Of_Loan']]\nfor col in cols:\n    train[[col]] = np.log1p(train[[col]])\n    test[[col]] = np.log1p(test[[col]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Interest_Rate']\nX = train[[col for col in train.columns if col!=\"Interest_Rate\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5,shuffle=False,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='multiclass',num_class=3,random_state=42,n_jobs=-1,verbose=1,)\nparams = {\"max_depth\":[4,6,8,10,-1],\n          \"learning_rate\":[0.01,0.03,0.05,0.1,0.3],\n          \"subsample\":[0.5,0.6,0.7,0.8,0.9],\n          \"colsample_bytree\":[0.5,0.6,0.7,0.8,0.9],\n          \"reg_alpha\":[0,0.25,0.5,1,2],\n          \"reg_lambda\":[0,0.25,0.5,1,2],\n          \"num_leaves\":[7,15,31,63,127],\n          \"min_data_in_leaf\":[1,3,5,7,10,25,50,75,100],\n          \"n_estimators\":list(range(50,1001,100))}\nrandom_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=kf.split(X,y),scoring='f1_weighted')\nrandom_search.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_,random_search.best_params_,random_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,6))\nser = pd.Series(random_search.best_estimator_.feature_importances_,X.columns).sort_values()\nser.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_1 = xgb.XGBClassifier(random_state=42,n_jobs=-1,verbosity=1,objective=\"multi:softmax\",num_class=3)\nparams = {\"max_depth\":[4,6,8,10],\n          \"n_estimators\":list(range(50,501,100)),\n          \"learning_rate\":[0.01,0.05,0.1,0.3],\n          \"subsample\":[0.5,0.6,0.7,0.8,0.9],\n          \"colsample_bytree\":[0.5,0.6,0.7,0.8,0.9],\n          \"reg_alpha\":[0.25,0.5,1],\n          \"reg_lambda\":[0.25,0.5,1]}\nrandom_search_1 = RandomizedSearchCV(estimator=clf_1,param_distributions=params,cv=kf.split(X,y),scoring='f1_weighted')\nrandom_search_1.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search_1.best_estimator_,random_search_1.best_params_,random_search_1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,6))\nser = pd.Series(random_search_1.best_estimator_.feature_importances_,X.columns).sort_values()\nser.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission['Interest_Rate_LGB'] = random_search.best_estimator_.predict(test)\nSubmission['Interest_Rate_XGB'] = random_search_1.best_estimator_.predict(test)\n#Submission.to_csv(\"Sub_78.csv\",index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission['Interest_Rate'] = Submission[[\"Interest_Rate_LGB\", \"Interest_Rate_XGB\"]].min(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.drop(['Interest_Rate_LGB','Interest_Rate_XGB'],axis=1,inplace=True)\nSubmission.to_csv(\"Sol_14.csv\",index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}